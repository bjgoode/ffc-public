{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import feature_selection, tree\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC, SVC, LinearSVR\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression, LassoCV\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "from itertools import product, combinations\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Data for Training...\n",
    "\n",
    "data_dir = '../.data'\n",
    "fp_train = '{}/train.csv'.format(data_dir)\n",
    "df_test = pd.read_csv(fp_train,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Feature Data...\n",
    "\n",
    "df_path = \"./../FFChallenge_v2/background.dta\"\n",
    "\n",
    "df_features = None\n",
    "with open(df_path, \"r\") as f:\n",
    "    df_features = pd.read_stata(f)\n",
    "    print df_features.head()\n",
    "    \n",
    "df_train = df_features.set_index('challengeID')\n",
    "df_train_na = df_train.replace('NA', np.NaN)\n",
    "df_train_na.cf4fint = pd.to_datetime(df_train_na.cf4fint)\n",
    "df_train_na_cols = df_train_na.columns[df_train_na.dtypes == 'object']\n",
    "df_train_na[df_train_na_cols] = df_train_na[df_train_na_cols].apply(lambda x: pd.to_numeric(x, errors = 'ignore'))\n",
    "\n",
    "df_train_no_obj = df_train_na[df_train_na.columns[df_train_na.dtypes != 'object']]\n",
    "final_cols = df_train_no_obj.columns[~ df_train_no_obj.isnull().all()]\n",
    "df_final = pd.DataFrame(df_train_no_obj[final_cols])\n",
    "print df_final.shape\n",
    "\n",
    "# Find number of unique values in each column. If unique == 1, then remove from final data frame.\n",
    "n = df_final.apply(lambda x: len(x.unique()))\n",
    "df_final = pd.DataFrame(df_final[df_final.columns[n>1]])\n",
    "print df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.hv5_wj9raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_interest = [\n",
    "    't5c13a',\n",
    "    't5c13b',\n",
    "    't5c13c',\n",
    "    't5b1a',\n",
    "    't5b1b',\n",
    "    't5b1c',\n",
    "    't5b1d',\n",
    "    't5b1e',\n",
    "    't5b1f',\n",
    "    't5b1g',\n",
    "    't5b1h',\n",
    "    't5b1i',\n",
    "    't5b1j',\n",
    "    't5b1k',\n",
    "    't5b1l',\n",
    "    't5b1m',\n",
    "    't5b1n',\n",
    "    't5b2c',\n",
    "    't5d5',\n",
    "    't5d6',\n",
    "    't5d7',\n",
    "]\n",
    "\n",
    "cols_child = [\n",
    "    'k5g1a',\n",
    "    'k5g1b',\n",
    "    'k5g1c',\n",
    "    'k5g1d',\n",
    "    'k5g1e',\n",
    "    'k5g2a',\n",
    "    'k5g2b',\n",
    "    'k5g2c',\n",
    "    'k5g2d',\n",
    "    'k5g2e',\n",
    "    'k5g2f',\n",
    "    'k5g2h',\n",
    "]\n",
    "\n",
    "cols_routine = [\n",
    "    'k5d1a',\n",
    "    'k5d1b',\n",
    "    'k5d1c',\n",
    "    'k5d1d',\n",
    "    'k5d1e',\n",
    "    'k5d1f',\n",
    "    'k5d1g',\n",
    "    'k5d1h',\n",
    "]\n",
    "\n",
    "cols_income = [\n",
    "    'm5j1',\n",
    "]\n",
    "\n",
    "other = [\n",
    "    'p5i1i'\n",
    "]\n",
    "\n",
    "home_visit = [\n",
    "#    'hv4l34',\n",
    "#    'hv5_wj9raw',\n",
    "#    'hv5_wj10raw',\n",
    "#    'hv5_wj9ss',\n",
    "#    'hv5_wj10ss',\n",
    "    'hv5_ppvtraw',\n",
    "#    'hv5_ppvtss',\n",
    "]\n",
    "\n",
    "cols = home_visit #cols_child + cols_routine + cols_income #+ other + cols_routine + cols_child + cols_interest\n",
    "\n",
    "df = pd.DataFrame(df_final[cols])\n",
    "#df = pd.DataFrame(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gpa'] = df_test.gpa\n",
    "teacher_survey = df.dropna()\n",
    "print 'Before cutting: {}'.format(teacher_survey.shape)\n",
    "\n",
    "def prepare(x):\n",
    "    if isinstance(x, basestring):\n",
    "        return int(x.split(' ')[0])\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "teacher_survey[cols] = pd.DataFrame(teacher_survey[cols].applymap(prepare))\n",
    "teacher_survey = teacher_survey[teacher_survey[cols[0]] > -9]\n",
    "#teacher_survey = teacher_survey[teacher_survey[cols[0]] > 0]\n",
    "teacher_survey = teacher_survey.applymap(lambda x: x * (x > 0))\n",
    "print 'After cutting: {}'.format(teacher_survey.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 400\n",
    "#reg = BayesianRidge()\n",
    "reg = LassoCV()\n",
    "#reg = tree.DecisionTreeRegressor()\n",
    "#reg = LinearRegression()\n",
    "X = teacher_survey[cols]\n",
    "Y = teacher_survey.gpa\n",
    "reg.fit(X.iloc[:b], Y.iloc[:b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_reg = reg.predict(X.iloc[b:])\n",
    "metrics.mean_squared_error(Y[b:], out_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(out_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = dict(zip(Y.unique(),range(len(Y.unique()))))\n",
    "keys_back = dict(zip(range(len(Y.unique())), Y.unique()))\n",
    "Y = Y.apply(lambda x: keys[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkNegative(x):\n",
    "    return isinstance(x, basestring) and x.startswith('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, pval = feature_selection.chi2(X,Y)\n",
    "feat_indx = X.columns[~np.isnan(chi2)]\n",
    "chi2_nona = chi2[~np.isnan(chi2)]\n",
    "pval_nona = pval[~np.isnan(chi2)]\n",
    "n_unique = X.apply(lambda x: len(x.unique()))\n",
    "n_nan = X.apply(lambda x: x.isnull().sum())\n",
    "#n_other = train.applymap(checkNegative).sum()\n",
    "\n",
    "feat_rank = pd.DataFrame({\n",
    "    'chi2': chi2_nona, \n",
    "    'pval': pval_nona,\n",
    "    'unqe': n_unique,\n",
    "    'n_nan': n_nan,\n",
    "#    'other': n_other,\n",
    "}, index = feat_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered = feat_rank.sort_values('pval')\n",
    "print ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ordered.index[0:11]\n",
    "cutoff = 500\n",
    "#clf = MultinomialNB()\n",
    "#clf = LinearSVC()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X[cols].iloc[:cutoff], Y[:cutoff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(map(lambda x: keys_back[x], out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = clf.predict(X[cols].iloc[cutoff:])\n",
    "plt.hist(out)\n",
    "Y[cutoff:].hist(alpha = 0.5)\n",
    "print metrics.classification_report(Y[cutoff:], out)\n",
    "print metrics.confusion_matrix(Y[cutoff:], out)\n",
    "\n",
    "#print metrics.brier_score_loss(Y[cutoff:], out)\n",
    "print metrics.mean_squared_error(Y[cutoff:].apply(lambda x: keys_back[x]), map(lambda x: keys_back[x] * 0 + 2.866, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis = 'cm1bsex'\n",
    "df_final[analysis].cat.codes.loc[df_test.index[df_test.gpa > 2.75]].hist(normed=True, alpha=0.5, bins = 10)\n",
    "df_final[analysis].cat.codes.loc[df_test.index[df_test.gpa <= 2.75]].hist(normed=True, alpha=0.5, bins = 10)\n",
    "#plt.ylim([0,.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['t5a2b'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Way forward: Make list of all binary measures (to create ORs) and then supplement with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
