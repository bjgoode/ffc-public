{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the following:\n",
    "\n",
    "1. In the past twelve months, did you receive free food or meals?\n",
    "2. In the past twelve months, were you ever hungry, but didn't eat because you couldn't afford enough food?\n",
    "3. In the past twelve months, did you ever not pay the full amount of rent or mortgage payments?\n",
    "4. In the past twelve months, were you evictd from your home or apartment for not paying the rent or mortgage?\n",
    "5. In the past twelve months, did you not pay the full amount of gas, oil, or electricity bill?\n",
    "6. In the past twelve months, was your gas or electric services ever turned off, or the heating oil company did not deliver oil, because there wasn't enough money to pay the bills?\n",
    "7. In the past twelve months, did you move in with other people even for a little while because of financial problems?\n",
    "8. In the past twelve months, did you stay at a shelter, in an abandoned building, an automobile or any other place not menat for regular housing, even for one night?\n",
    "9. IN the past twelve months, was there anyone in your household who needed to see a doctor or go to the hospital but couldn't go because of cost?\n",
    "10. IN the past twelve months, was your telephone service cancelled or disconnected by the telephone company because there wasn't enough money to pay the bill?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import feature_selection, tree\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression, LassoCV\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "from itertools import product, combinations\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Data for Training...\n",
    "\n",
    "data_dir = '../.data'\n",
    "fp_train = '{}/train.csv'.format(data_dir)\n",
    "df_test = pd.read_csv(fp_train,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Feature Data...\n",
    "\n",
    "df_path = \"./../FFChallenge_v2/background.dta\"\n",
    "\n",
    "df_features = None\n",
    "with open(df_path, \"r\") as f:\n",
    "    df_features = pd.read_stata(f)\n",
    "    print df_features.head()\n",
    "    \n",
    "df_train = df_features.set_index('challengeID')\n",
    "df_train_na = df_train.replace('NA', np.NaN)\n",
    "df_train_na.cf4fint = pd.to_datetime(df_train_na.cf4fint)\n",
    "df_train_na_cols = df_train_na.columns[df_train_na.dtypes == 'object']\n",
    "df_train_na[df_train_na_cols] = df_train_na[df_train_na_cols].apply(lambda x: pd.to_numeric(x, errors = 'ignore'))\n",
    "\n",
    "df_train_no_obj = df_train_na[df_train_na.columns[df_train_na.dtypes != 'object']]\n",
    "final_cols = df_train_no_obj.columns[~ df_train_no_obj.isnull().all()]\n",
    "df_final = pd.DataFrame(df_train_no_obj[final_cols])\n",
    "print df_final.shape\n",
    "\n",
    "# Find number of unique values in each column. If unique == 1, then remove from final data frame.\n",
    "n = df_final.apply(lambda x: len(x.unique()))\n",
    "df_final = pd.DataFrame(df_final[df_final.columns[n>1]])\n",
    "print df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_interest = [\n",
    "#    'm2h19e',\n",
    "#    'm2h19d',\n",
    "#    'm2h19f',\n",
    "#    'm2h19g',\n",
    "#    'm2h19h',\n",
    "#    'f2h17e',\n",
    " #   'f2h17d',\n",
    "#    'f2h17f',\n",
    "#    'f2h17g',\n",
    "#    'f2h17h',\n",
    "    'm2h19a',\n",
    "    'm2h19b',\n",
    "    'm2h19c',\n",
    "    'm2h19d',\n",
    "    'm2h19e',\n",
    "    'm2h19f',\n",
    "    'm2h19g',\n",
    "    'm2h19h',\n",
    "    'm2h19i',\n",
    "    'm2h19j',\n",
    "    'm2h19k',\n",
    "#    'f3i23c',\n",
    "#    'f3i23b',\n",
    "#    'f3i23d',\n",
    "    'm4i23a',\n",
    "    'm4i23b',\n",
    "    'm4i23c',\n",
    "    'm4i23d',\n",
    "    'm4i23e',\n",
    "    'm4i23f',\n",
    "    'm4i23g',\n",
    "    'm4i23h',\n",
    "    'm4i23i',\n",
    "    'm4i23j',\n",
    "    'm4i23k',\n",
    "    'm5f23a',\n",
    "    'm5f23b',\n",
    "    'm5f23c',\n",
    "    'm5f23d',\n",
    "    'm5f23e',\n",
    "    'm5f23f',\n",
    "    'm5f23g',\n",
    "    'm5f23h',\n",
    "    'm5f23i',\n",
    "    'm5f23j',\n",
    "    'm5f23k',\n",
    "#    'n5g1a',\n",
    "#    'n5g1b',\n",
    "#    'n5g1c',\n",
    "#    'n5g1d',\n",
    "#    'n5g1e',\n",
    "#    'n5g1f',\n",
    "#    'n5g1g',\n",
    "#    'n5g1h',\n",
    "#    'n5g1i',\n",
    "#    'n5g1j',\n",
    "]\n",
    "\n",
    "liveIn = pd.DataFrame(df_final.m5a2.apply(lambda x: int(not x.startswith('1'))))\n",
    "\n",
    "df = pd.DataFrame(df_final[cols_interest])\n",
    "df = df.applymap(lambda x: int(x.split(' ')[0]))\n",
    "df = df.applymap(lambda x: x * (x >= 0))\n",
    "\n",
    "df['cum_sum'] = df.sum(axis=1)\n",
    "df['mat_hds'] = df[cols_interest[22:]].apply(lambda x: x[x==1].sum()/11., axis=1)\n",
    "df['mat_hds_diff'] = df[cols_interest[11:22]].apply(lambda x: x[x==1].sum()/11., axis=1)\n",
    "df['mat_hds_diff2'] = df[cols_interest[:11]].apply(lambda x: x[x==1].sum()/11., axis=1)\n",
    "df['regression'] = reg.predict(df[['mat_hds','mat_hds_diff','mat_hds_diff2']])\n",
    "df = df.drop(df.index[(df.cum_sum < 0)])\n",
    "df = df.drop(liveIn.index[liveIn.m5a2 == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.n5g1b.sum()\n",
    "df[df.n5g1b > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df_final.m5a2.loc[df[df.n5g1b > 0].index].value_counts()\n",
    "print df_final.m5a2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df_final.f5a2.loc[df[df.n5g1b > 0].index].value_counts()\n",
    "print df_final.f5a2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df_final.f5a2.loc[df[(df.m5f23a == 0)].index].value_counts()\n",
    "print df_final.f5a2.loc[df[(df.m5f23a == 0) & (df.n5g1b == 0)].index].value_counts()\n",
    "print df_final.f5a2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matHard = df_test.materialHardship.loc[df.index].dropna()\n",
    "matHard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc[matHard.index]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = train.apply(lambda x: x.cat.codes)\n",
    "#X['sum'] = X.sum(axis=1)\n",
    "X = pd.DataFrame(train)\n",
    "Y = matHard\n",
    "keys = dict(zip(Y.unique(),range(len(Y.unique()))))\n",
    "keys_back = dict(zip(range(len(Y.unique())), Y.unique()))\n",
    "Y = Y.apply(lambda x: keys[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkNegative(x):\n",
    "    return isinstance(x, basestring) and x.startswith('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chi2, pval = feature_selection.chi2(X,Y)\n",
    "feat_indx = X.columns[~np.isnan(chi2)]\n",
    "chi2_nona = chi2[~np.isnan(chi2)]\n",
    "pval_nona = pval[~np.isnan(chi2)]\n",
    "n_unique = X.apply(lambda x: len(x.unique()))\n",
    "n_nan = X.apply(lambda x: x.isnull().sum())\n",
    "#n_other = train.applymap(checkNegative).sum()\n",
    "\n",
    "feat_rank = pd.DataFrame({\n",
    "    'chi2': chi2_nona, \n",
    "    'pval': pval_nona,\n",
    "    'unqe': n_unique,\n",
    "    'n_nan': n_nan,\n",
    "#    'other': n_other,\n",
    "}, index = feat_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered = feat_rank.sort_values('pval')\n",
    "print ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = ordered.index.isin(['cum_sum'])\n",
    "#cols = ordered.index[~mask]\n",
    "cols = ordered.index[:10]\n",
    "cutoff = 500\n",
    "#clf = MultinomialNB()\n",
    "clf = LinearSVC()\n",
    "#clf = SVC(kernel = 'sigmoid', tol=.000001, verbose = True)\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X[cols].iloc[:cutoff], Y[:cutoff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = clf.predict(X[cols].iloc[cutoff:])\n",
    "plt.hist(out)\n",
    "Y[cutoff:].hist(alpha = 0.5)\n",
    "print metrics.classification_report(Y[cutoff:], out)\n",
    "print metrics.confusion_matrix(Y[cutoff:], out)\n",
    "\n",
    "#print metrics.brier_score_loss(Y[cutoff:], out)\n",
    "print metrics.mean_squared_error(Y[cutoff:].apply(lambda x: keys_back[x]), map(lambda x: keys_back[x], out) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for Who's Who in The PCG slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whoWith = pd.DataFrame(df_test.materialHardship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whoWith['m5a2'] = df_final.m5a2\n",
    "whoWith['f5a2'] = df_final.f5a2\n",
    "whoWith['n5a5'] = df_final.n5a5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print whoWith.n5a5.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print whoWith[whoWith.materialHardship.apply(lambda x: str(x).startswith('0.54'))].n5a5.value_counts()\n",
    "print whoWith[whoWith.materialHardship.apply(lambda x: str(x).startswith('0.45'))].n5a5.value_counts()\n",
    "print whoWith[whoWith.materialHardship.apply(lambda x: str(x).startswith('0.36'))].n5a5.value_counts()\n",
    "print whoWith[whoWith.materialHardship.apply(lambda x: str(x).startswith('0.27'))].n5a5.value_counts()\n",
    "print whoWith[whoWith.materialHardship.apply(lambda x: str(x).startswith('0.18'))].n5a5.value_counts()\n",
    "print whoWith[whoWith.materialHardship.apply(lambda x: str(x).startswith('0.09'))].n5a5.value_counts()\n",
    "print whoWith[whoWith.materialHardship.apply(lambda x: str(x) == '0.0')].n5a5.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whoWith[whoWith.n5a5.apply(lambda x: str(x).startswith('1'))].materialHardship.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whoWith[['m5a2','f5a2', 'n5a5']] = whoWith[['m5a2','f5a2', 'n5a5']].applymap(lambda x: abs(int(x.split(' ')[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whoWith = whoWith.dropna()\n",
    "whoWith['code'] = whoWith[['m5a2','f5a2','n5a5']].apply(lambda x: ''.join(x.astype(int).astype(str)), axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(whoWith.code,whoWith.materialHardship,'.',markersize = 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whoDist = whoWith.groupby(['code', 'materialHardship']).code.count()\n",
    "z = [(x[0],x[1],y) for x,y in whoDist.iteritems()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xd,yd,zd = zip(*z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xd,yd,zd)\n",
    "plt.xlim([100,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat = pd.concat([train.mat_hds, matHard], axis = 1)\n",
    "nums = scat.groupby(['mat_hds', 'materialHardship']).mat_hds.count()\n",
    "z = [(x[0],x[1],y) for x,y in nums.iteritems()]\n",
    "xd,yd,zd = zip(*z)\n",
    "plt.scatter(xd,yd,zd)\n",
    "plt.xlabel('initial')\n",
    "plt.ylabel('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_comp = pd.DataFrame(df[['mat_hds', 'mat_hds_diff', 'mat_hds_diff2']])\n",
    "df_comp['true'] = df_test.materialHardship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_comp = df_comp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 500\n",
    "#reg = BayesianRidge(tol = 0.00000001)\n",
    "reg = LassoCV()\n",
    "#reg = LinearRegression()\n",
    "X = df_comp[[\n",
    "    'mat_hds', \n",
    "    'mat_hds_diff',\n",
    "    'mat_hds_diff2'\n",
    "]]\n",
    "Y = df_comp['true']\n",
    "reg.fit(X.iloc[b:], Y.iloc[b:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_reg = reg.predict(X.iloc[:b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(Y[:b], out_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(out_reg,Y[b:],'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: to-do\n",
    "» need to combine with other primary-care-giver and father information.\n",
    "» need to feed in the results from the linear regression (which we know to be incorrect) and try to correct them with the classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
